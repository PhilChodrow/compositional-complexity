---
title: "opt"
author: "phil"
date: "April 8, 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

# Introduction

## This Document

While in practice we'd be interested in finding spatial structure in more complicated data sets, Phil has been working on understanding this algorithm and its behavior on a very simple, toy data set for now. The data is a randomly generated set of binary probability distributions along one spatial dimension. The spatial structure is a Gaussian mixture, which means that it should be very easy for the model to find. 

```{r libraries}
library(dplyr)
library(compx)
library(alabama)
library(ggplot2)
library(tidyr)
```



```{r make_data, cache=FALSE}
# Data dimensions
i <- 30
j <- 5
n <- 1
k <- 20
data_dims <- list(I = i, J = j, K = k, n = n)
data <- random_1d_data(data_dims)
```

```{r model, cache=FALSE}
model_dims <- get_dims(data, K = 7)
problem <- make_problem(data, model_dims)
```

```{r first_pars, cache=FALSE}

pars <- warm_start(data, model_dims)

vec <- to_vec(pars)
```

The warm start looks like this: 

```{r viz, cache = FALSE}

viz_data  <- data$P %>% data.frame %>% tbl_df %>%
	mutate(pos = row.names(.),
		   type = 'data')

viz_preds <- Psi(X = data$X, vec = vec, dims = model_dims) %>%
 	data.frame %>% tbl_df %>%
	mutate(pos = row.names(.),
		   type = 'warm start')

viz_tbl <- rbind(viz_data, viz_preds) %>% gather(comp, p, X1:X5) %>%
	mutate(pos = as.integer(pos) / 10)
	
ggplot(viz_tbl, aes(x = comp, y = pos)) +
	geom_tile(aes(fill = p)) +
	scale_fill_gradient(low = "white", high = "steelblue", limits = c(0,1)) + 
	facet_wrap(~type) + theme_minimal() + 
	theme(axis.title.x = element_blank(),
		  axis.text.x=element_blank(),
		  axis.text.y=element_blank(),
		  axis.title.y = element_blank()) 

```

```{r solve, cache=FALSE, echo=FALSE, warning=FALSE, message=FALSE}
opt_pars <- auglag(par = vec,
   fn = problem$objective,
   heq = problem$heq,
   hin = problem$hin,
   control.optim = list(reltol = .0001),
   control.outer=list(kkt2.check=FALSE,
   				   eps = .001,
   				   trace = TRUE))
```

```{r viz_results, cache = FALSE}

viz_data  <- data$P %>% data.frame %>% tbl_df %>%
	mutate(pos = row.names(.),
		   type = 'data')

viz_preds <- Psi(X = data$X, vec = opt_pars$par, dims = model_dims) %>%
 	data.frame %>% tbl_df %>%
	mutate(pos = row.names(.),
		   type = 'modeled')

viz_tbl <- rbind(viz_data, viz_preds) %>% gather(comp, p, X1:X5) %>%
	mutate(pos = as.integer(pos) / 10)
	
ggplot(viz_tbl, aes(x = comp, y = pos)) +
	geom_tile(aes(fill = p)) +
	scale_fill_gradient(low = "white", high = "steelblue", limits = c(0,1)) + 
	facet_wrap(~type) + theme_minimal() + 
	theme(axis.title.x = element_blank(),
		  axis.text.x=element_blank(),
		  axis.text.y=element_blank(),
		  axis.title.y = element_blank()) 

```

Now let's view the parameters. 

```{r params, cache = FALSE}

from_vec(opt_pars$par, model_dims)

```

# TODO

- **Warm starts.**: *These possible improve quality, but don't seem (anecdotally) to have a huge impact on performance.* 
- Anecdotally, seems like this algorithm has problems reasoning about more J > 2: when I set J = 3, it has a tendency to send one of the parameters equal to zero and model with the remainder. 
- Clean up the interface so that basic tasks are easier
	- Generate problem, including warm-start initial values
	- Solve problem
	- Make and visualize the predictions involved
	- Easily retrieve the objective value
	- Test repeatedly to e.g. compare objective values
- Math 
	- Optimization (for speed)
		- Convert handling of Q to eliminate equality constraints
		- Consider normalizing b, and optionally bounding components away from 0
		- Compute the gradient again
		- Can we make it cheaper to compute the objective function?
	

